{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa476b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import onnxruntime as rt\n",
    "import onnx\n",
    "from skl2onnx.common.data_types import FloatTensorType\n",
    "from skl2onnx import to_onnx\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from skl2onnx import convert_sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e81b41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's load the dataset\n",
    "data = pd.read_csv('data/investigation_train_large_checked.csv')\n",
    "details = pd.read_csv('data/data_description.csv', encoding='latin1')\n",
    "\n",
    "# Rename columns to english for ease of use\n",
    "data.rename(columns=dict(zip(details['Feature (nl)'], details['Feature (en)'])), inplace=True)\n",
    "\n",
    "# Let's specify the features and the target\n",
    "y = data['checked']\n",
    "X = data.drop(['checked'], axis=1)\n",
    "X = X.astype(np.float32)\n",
    "\n",
    "# Let's split the dataset into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077a789d",
   "metadata": {},
   "source": [
    "## Here we will look at different features and their format to discover potential validity problems in the data\n",
    "\n",
    "### First, we will look at the features related to the contacts with the municipality\n",
    "\n",
    "#### Since we know all of those attributes represent numbers of appointments, signaling requirement with administrative help, we expect this attribute to have little impact on the risk calculation, and thus will use metamorphic testing on this relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ec2e96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define metamorphic transformations\n",
    "def perturbation(df, cols):\n",
    "    df_perturbed = df.copy()\n",
    "    for col in cols:\n",
    "        df_perturbed[col] = df[col] + np.random.normal(0, df[col].std(), size=df[col].shape)\n",
    "    return df_perturbed\n",
    "\n",
    "def permutation(df, cols):\n",
    "    df_permuted = df.copy()\n",
    "    for col in cols:\n",
    "        df_permuted[col] = np.random.permutation(df[col])   \n",
    "    return df_permuted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f354693f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Commented out because this just visualises desired fields\n",
    "if False: \n",
    "  plt.clf()\n",
    "  apps = [col for col in data.columns if 'appointment' in col and 'number' not in col and 'combined' not in col]\n",
    "  # Combine Appointment values in a new feature\n",
    "  data[\"appointment_combined\"] = data[apps].sum(axis=1)\n",
    "  data.boxplot(column=['appointment_combined'])\n",
    "  plt.show()\n",
    "  data.drop(columns='appointment_combined', inplace=True)\n",
    "\n",
    "  # Address Exploration\n",
    "\n",
    "  plt.clf()\n",
    "  adds = [col for col in data.columns if 'address' in col]\n",
    "  for row in details.itertuples():\n",
    "      if row[3] in adds:\n",
    "          print(f\"{row[3]} :::: {row[6]}\")\n",
    "  data.hist(column=adds, figsize=(25, 15))\n",
    "  plt.show()\n",
    "\n",
    "  plt.clf()\n",
    "  contacts = [col for col in data.columns if 'contacts' in col]\n",
    "  for row in details.itertuples():\n",
    "      if row[3] in contacts:\n",
    "          print(f\"{row[3]} :::: {row[6]}\")\n",
    "  data.hist(column=contacts, figsize=(25, 15))\n",
    "  plt.show()\n",
    "\n",
    "  plt.clf()\n",
    "  obstacles = [col for col in data.columns if 'obstacle' in col]\n",
    "  for row in details.itertuples():\n",
    "      if row[3] in obstacles:\n",
    "          print(f\"{row[3]} :::: {row[6]}\")\n",
    "  data.hist(column=obstacles, figsize=(25, 15))\n",
    "  plt.show()\n",
    "\n",
    "  plt.clf()\n",
    "  avail = [col for col in data.columns if 'availability' in col]\n",
    "  for row in details.itertuples():\n",
    "      if row[3] in avail:\n",
    "          print(f\"{row[3]} :::: {row[6]}\")\n",
    "  data.hist(column=avail, figsize=(25, 15))\n",
    "  plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# Set up metamorphic relationships\n",
    "metamorphic_relations=[\n",
    "    {'name': 'appointments', 'target': lambda df: [col for col in df.columns if 'appointment' in col],\n",
    "      'transformations': [{'name': 'permutation', 'function': permutation}, {'name': 'perturbation', 'function': perturbation}]},\n",
    "    {'name': 'address_numerical', 'target': lambda df: [col for col in df.columns if 'address_number' in col or 'address_days' in col],\n",
    "      'transformations': [{'name': 'permutation', 'function': permutation}, {'name': 'perturbation', 'function': perturbation}]},\n",
    "    {'name': 'address_binary', 'target': lambda df: [col for col in df.columns if 'address_latest' in col or 'address_unique' in col],\n",
    "      'transformations': [{'name': 'permutation', 'function': permutation}]},\n",
    "]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025f1401",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define equivalent partitions\n",
    "partition_tests = [\n",
    "    [\n",
    "    # Related to obstacles\n",
    "    {\"name\": \"fin_0\", \"condition\": lambda df: df['obstacle_financial_problems'] < 0.5},\n",
    "    {\"name\": \"fin_1\", \"condition\": lambda df: df['obstacle_financial_problems'] > 0.5}\n",
    "    ],[\n",
    "    {\"name\": \"psyc_0\", \"condition\": lambda df: df['obstacle_hist_psychological_problems'] < 0.5 and df['obstacle_psychological_problems'] < 0.5},\n",
    "    {\"name\": \"psyc_1\", \"condition\": lambda df: df['obstacle_hist_psychological_problems'] > 0.5 and df['obstacle_psychological_problems'] > 0.5}\n",
    "    ],[\n",
    "    {\"name\": \"lan_0\", \"condition\": lambda df: df['obstacle_hist_language'] < 0.5},\n",
    "    {\"name\": \"lan_1\", \"condition\": lambda df: df['obstacle_hist_language'] > 0.5}\n",
    "    ],[\n",
    "    {\"name\": \"addict_0\", \"condition\": lambda df: df['obstacle_hist_addiction_problems'] < 0.5},\n",
    "    {\"name\": \"addict_1\", \"condition\": lambda df: df['obstacle_hist_addiction_problems'] > 0.5}\n",
    "    ],\n",
    "    # Related to availability deviations\n",
    "    [\n",
    "    {\"name\": \"social_0\", \"condition\": lambda df: df['availability_recent_deviating_due_to_social_social_situation'] < 0.5},\n",
    "    {\"name\": \"social_1\", \"condition\": lambda df: df['availability_recent_deviating_due_to_social_social_situation'] > 0.5}\n",
    "    ],[\n",
    "    {\"name\": \"medical_0\", \"condition\": lambda df: df['availability_recent_deviating_due_to_medical_circumstances'] < 0.5},\n",
    "    {\"name\": \"medical_1\", \"condition\": lambda df: df['availability_recent_deviating_due_to_medical_circumstances'] > 0.5}\n",
    "    ],\n",
    "\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b071e1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply metamorphic testing\n",
    "\n",
    "for metamorphic in metamorphic_relations:\n",
    "    target_columns = metamorphic['target'](data_sample)\n",
    "    print(f\"Test: {metamorphic[\"name\"]}\")\n",
    "\n",
    "\n",
    "    for transformation in metamorphic['transformations']:\n",
    "        \n",
    "        print(f\"{transformation['name']} test\")\n",
    "        acc_list = []\n",
    "        for run in range(10):\n",
    " \n",
    "            data_sample = X_test.sample(n=500)\n",
    "\n",
    "            tranf_data = transformation['function'](data_sample, target_columns)\n",
    "            tranf_labels = y_test.loc[tranf_data.index]\n",
    "\n",
    "            if not tranf_data.empty:\n",
    "            # Predictions using the model\n",
    "                predictions = model.predict(tranf_data)\n",
    "\n",
    "                # Calculate accuracy for this partition\n",
    "                accuracy = accuracy_score(tranf_labels, predictions)\n",
    "                acc_list.append(accuracy)\n",
    "\n",
    "                # Print transformation details\n",
    "                print(f\"Run: {run}\")\n",
    "                print(f\"Accuracy: {accuracy:.2f}\")\n",
    "                print(f\"Predictions: {np.unique(predictions, return_counts=True)}\\n\")\n",
    "                print()\n",
    "\n",
    "        print(\"Final Results\")\n",
    "        print(f\"Average accuracy: {np.mean(acc_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68eaf03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply equivalent partitioning\n",
    "# Needs some work with multiple train/test splits\n",
    "for partitions in partition_tests:\n",
    "    for partition in partitions:\n",
    "        partition_data = data_sample[partition[\"condition\"](data_sample)]\n",
    "        partition_indices = partition_data.index  # Get the indices of the partition\n",
    "        partition_labels = y_test.loc[partition_indices]  # Get the actual labels for the partition\n",
    "\n",
    "        if not partition_data.empty:\n",
    "            # Predictions using the model\n",
    "            predictions = model.predict(partition_data)\n",
    "\n",
    "            # Calculate accuracy for this partition\n",
    "            accuracy = accuracy_score(partition_labels, predictions)\n",
    "\n",
    "            # Print partition details\n",
    "            print(f\"Partition: {partition['name']}\")\n",
    "            print(f\"Number of data points: {len(partition_data)}\")\n",
    "            print(f\"Accuracy: {accuracy:.2f}\")\n",
    "            print(f\"Predictions: {np.unique(predictions, return_counts=True)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Select data based on variance (not the final version yet, for now just for testing)\n",
    "selector = VarianceThreshold()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eaf5a3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a gradient boosting classifier\n",
    "classifier = GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a pipeline object with our selector and classifier\n",
    "# NOTE: You can create custom pipeline objects but they must be registered to onnx or it will not recognise them\n",
    "# Because of this we recommend using the onnx known objects as defined in the documentation\n",
    "pipeline = Pipeline(steps=[('feature selection', selector), ('classification', classifier)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the original model:  0.9456040480708412\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Let's train a simple model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Let's evaluate the model\n",
    "y_pred = pipeline.predict(X_test)\n",
    "original_accuracy = accuracy_score(y_test, y_pred)\n",
    "print('Accuracy of the original model: ', original_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's convert the model to ONNX\n",
    "onnx_model = convert_sklearn(\n",
    "    pipeline, initial_types=[('X', FloatTensorType((None, X.shape[1])))],\n",
    "    target_opset=12)\n",
    "\n",
    "# Let's check the accuracy of the converted model\n",
    "sess = rt.InferenceSession(onnx_model.SerializeToString())\n",
    "y_pred_onnx =  sess.run(None, {'X': X_test.values.astype(np.float32)})\n",
    "\n",
    "accuracy_onnx_model = accuracy_score(y_test, y_pred_onnx[0])\n",
    "print('Accuracy of the ONNX model: ', accuracy_onnx_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f68f63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's save the model\n",
    "onnx.save(onnx_model, \"model/gboost.onnx\")\n",
    "\n",
    "# Let's load the model\n",
    "new_session = rt.InferenceSession(\"model/gboost.onnx\")\n",
    "\n",
    "# Let's predict the target\n",
    "y_pred_onnx2 =  new_session.run(None, {'X': X_test.values.astype(np.float32)})\n",
    "\n",
    "accuracy_onnx_model = accuracy_score(y_test, y_pred_onnx2[0])\n",
    "print('Accuracy of the ONNX model: ', accuracy_onnx_model)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
